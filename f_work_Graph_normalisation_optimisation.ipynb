{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0rFvwSFh9Y3Waod8pWKDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koad7/uol_final/blob/main/f_work_Graph_normalisation_optimisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yvVmrqtX9YPm"
      },
      "outputs": [],
      "source": [
        "def create_graph_from_dataframe_normalisation(df):\n",
        "    KG = nx.DiGraph()\n",
        "    node_to_osm_id = {}  # For deduplication based on osm_id\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Standardize Node Labels\n",
        "        name = row['name'].lower().strip() if not pd.isnull(row['name']) else None\n",
        "        city = row['city'].lower().strip() if not pd.isnull(row['city']) else None\n",
        "        country = row['country'].lower().strip() if not pd.isnull(row['country']) else None\n",
        "        sub_region = row['sub-region'].lower().strip() if not pd.isnull(row['sub-region']) else None\n",
        "        region = row['region'].lower().strip() if not pd.isnull(row['region']) else None\n",
        "\n",
        "        # Node Deduplication based on osm_id\n",
        "        if name and row['osm_id'] in node_to_osm_id.values():\n",
        "            continue\n",
        "\n",
        "        # Add nodes only if they are not None\n",
        "        if name:\n",
        "            KG.add_node(name, alternative_names=row['alternative_names'], region=row['region'], osm_id=row['osm_id'], labels=name)\n",
        "            node_to_osm_id[name] = row['osm_id']\n",
        "        if city:\n",
        "            KG.add_node(city, region=row['region'], state=row['state'], labels=city)\n",
        "        if country:\n",
        "            KG.add_node(country, capital=row['capital'], region=row['region'], related_places=get_related_places(country), labels=country)\n",
        "        if sub_region:\n",
        "            KG.add_node(sub_region, region=row['region'], labels=sub_region)\n",
        "        if region:\n",
        "            KG.add_node(region, labels=region)\n",
        "\n",
        "        # Add edges only between existing nodes\n",
        "        if name and city and KG.has_node(name) and KG.has_node(city):\n",
        "            KG.add_edge(name, city, relation=\"is_in\", labels=f'{name} IS_IN {city}')\n",
        "        if city and country and KG.has_node(city) and KG.has_node(country) and city != row['capital']:\n",
        "            KG.add_edge(city, country, relation=\"is_in\", labels=f'{city} IS_IN {country}')\n",
        "        if country and sub_region and KG.has_node(country) and KG.has_node(sub_region):\n",
        "            KG.add_edge(country, sub_region, relation=\"is_in\", labels=f'{country} IS_IN {sub_region}')\n",
        "        if sub_region and region and KG.has_node(sub_region) and KG.has_node(region):\n",
        "            KG.add_edge(sub_region, region, relation=\"is_in\", labels=f'{sub_region} IS_IN {region}')\n",
        "\n",
        "    return KG\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(node, tokenizer, model):\n",
        "    inputs = tokenizer(node, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    node_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    return node, node_embedding\n",
        "\n",
        "\n",
        "def distillmBERT_KGE(KG):\n",
        "    # Initialize DistilBERT tokenizer and model\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
        "    model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "\n",
        "    # Initialize an empty dictionary to store embeddings\n",
        "    distilmbert_embeddings = {}\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        future_to_node = {executor.submit(get_embedding, node, tokenizer, model): node for node in KG.nodes}\n",
        "        for future in as_completed(future_to_node):\n",
        "            node = future_to_node[future]\n",
        "            try:\n",
        "                node, node_embedding = future.result()\n",
        "                distilmbert_embeddings[node] = np.array(node_embedding)  # Ensure it's a NumPy array\n",
        "            except Exception as exc:\n",
        "                print(f\"{node} generated an exception: {exc}\")\n",
        "\n",
        "    # Embedding Similarity for Node Merging\n",
        "    nodes = list(KG.nodes)\n",
        "    for i, node1 in enumerate(nodes):\n",
        "        for j, node2 in enumerate(nodes[i+1:]):\n",
        "            similarity = cosine_similarity([distilmbert_embeddings[node1]], [distilmbert_embeddings[node2]])\n",
        "            if similarity > 0.9:  # Threshold for merging\n",
        "                # Merge nodes\n",
        "                merge_nodes(KG, node1, node2, distilmbert_embeddings)\n",
        "\n",
        "    return distilmbert_embeddings"
      ],
      "metadata": {
        "id": "pP_Gj9pw9fvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_nodes(graph, primary, secondary, embeddings):\n",
        "    # Transfer edges from secondary to primary\n",
        "    for neighbor in list(graph.neighbors(secondary)):\n",
        "        if not graph.has_edge(primary, neighbor):\n",
        "            graph.add_edge(primary, neighbor, **graph[secondary][neighbor])\n",
        "\n",
        "    # Update attributes of the primary node\n",
        "    for key, value in graph.nodes[secondary].items():\n",
        "        if key in graph.nodes[primary]:\n",
        "            if isinstance(graph.nodes[primary][key], list):\n",
        "                graph.nodes[primary][key].extend(value)\n",
        "            elif isinstance(graph.nodes[primary][key], set):\n",
        "                graph.nodes[primary][key].update(value)\n",
        "            # Add more types as needed\n",
        "        else:\n",
        "            graph.nodes[primary][key] = value\n",
        "\n",
        "    # Update the embeddings for the primary node (average the embeddings)\n",
        "    embeddings[primary] = (embeddings[primary] + embeddings[secondary]) / 2\n",
        "\n",
        "    # Remove the secondary node\n",
        "    graph.remove_node(secondary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def distillmBERT_KGE(KG):\n",
        "    # Initialize DistilBERT tokenizer and model\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
        "    model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "\n",
        "    # Initialize an empty dictionary to store embeddings\n",
        "    distilmbert_embeddings = {}\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        future_to_node = {executor.submit(get_embedding, node, tokenizer, model): node for node in KG.nodes}\n",
        "        for future in as_completed(future_to_node):\n",
        "            node = future_to_node[future]\n",
        "            try:\n",
        "                node, node_embedding = future.result()\n",
        "                distilmbert_embeddings[node] = np.array(node_embedding)  # Ensure it's a NumPy array\n",
        "            except Exception as exc:\n",
        "                print(f\"{node} generated an exception: {exc}\")\n",
        "\n",
        "    return distilmbert_embeddings"
      ],
      "metadata": {
        "id": "OgHNtGiT9oe4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}